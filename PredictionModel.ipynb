{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pkgs\n",
    "%pip install pandas numpy scikit-learn jupyter matplotlib seaborn xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42e543d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data columns:\n",
      "['Race_Time', 'Race_ID', 'Course', 'Distance', 'distanceYards', 'Prize', 'Going', 'Horse', 'Trainer', 'Jockey', 'betfairSP', 'Position', 'timeSecs', 'pdsBeaten', 'NMFP', 'Runners', 'Age', 'Speed_PreviousRun', 'Speed_2ndPreviousRun', 'NMFPLTO', 'MarketOdds_PreviousRun', 'MarketOdds_2ndPreviousRun', 'TrainerRating', 'JockeyRating', 'daysSinceLastRun', 'SireRating', 'DamsireRating', 'meanRunners']\n",
      "\n",
      "Test data columns:\n",
      "['Race_Time', 'Race_ID', 'Course', 'Distance', 'distanceYards', 'Prize', 'Going', 'Horse', 'Trainer', 'Jockey', 'betfairSP', 'Position', 'timeSecs', 'pdsBeaten', 'NMFP', 'Runners', 'Age', 'Speed_PreviousRun', 'Speed_2ndPreviousRun', 'NMFPLTO', 'MarketOdds_PreviousRun', 'MarketOdds_2ndPreviousRun', 'TrainerRating', 'JockeyRating', 'daysSinceLastRun', 'SireRating', 'DamsireRating', 'meanRunners']\n",
      "Train Data Sample:\n",
      "        Race_Time  Race_ID         Course Distance  distanceYards  Prize  \\\n",
      "0  2/1/2024 19:00     1935  Wolverhampton   6f 20y           1340   4972   \n",
      "1  2/1/2024 19:00     1935  Wolverhampton   6f 20y           1340   4972   \n",
      "2  2/1/2024 19:00     1935  Wolverhampton   6f 20y           1340   4972   \n",
      "3  2/1/2024 19:00     1935  Wolverhampton   6f 20y           1340   4972   \n",
      "4  2/1/2024 19:00     1935  Wolverhampton   6f 20y           1340   4972   \n",
      "\n",
      "      Going            Horse          Trainer             Jockey  ...  \\\n",
      "0  Standard     Intervention  Michael Appleby      Aiden Brookes  ...   \n",
      "1  Standard  Evocative Spark  Darryll Holland  Christian Howarth  ...   \n",
      "2  Standard        Sluzewiec      Scott Dixon     Kieran O'Neill  ...   \n",
      "3  Standard          Muscika    David O'Meara          Mark Winn  ...   \n",
      "4  Standard        Venturous     David Barron      David Probert  ...   \n",
      "\n",
      "   Speed_2ndPreviousRun   NMFPLTO  MarketOdds_PreviousRun  \\\n",
      "0                  70.0  0.875000                   11.03   \n",
      "1                  48.0  0.181818                   42.67   \n",
      "2                  59.0  0.000000                  141.13   \n",
      "3                  73.0  0.333333                    8.97   \n",
      "4                  62.0  0.090909                   44.84   \n",
      "\n",
      "   MarketOdds_2ndPreviousRun  TrainerRating  JockeyRating  daysSinceLastRun  \\\n",
      "0                       3.60       2.377268      2.925027               7.0   \n",
      "1                       4.19       2.401274      2.611219              13.0   \n",
      "2                      86.83       2.824967      2.925073              50.0   \n",
      "3                      12.86       2.317504      2.534689              38.0   \n",
      "4                      18.20       2.292027      2.448742              24.0   \n",
      "\n",
      "   SireRating  DamsireRating  meanRunners  \n",
      "0    2.933961       0.467149        10.25  \n",
      "1    1.934009       0.459547        10.25  \n",
      "2    2.411403       0.456616         8.00  \n",
      "3    2.639010       0.462397        10.00  \n",
      "4    2.494198       0.450770        11.00  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Test Data Sample:\n",
      "        Race_Time  Race_ID     Course   Distance  distanceYards  Prize  \\\n",
      "0  1/1/2025 14:24       58  Newcastle  1m 2f 42y           2242   5234   \n",
      "1  1/1/2025 14:24       58  Newcastle  1m 2f 42y           2242   5234   \n",
      "2  1/1/2025 14:24       58  Newcastle  1m 2f 42y           2242   5234   \n",
      "3  1/1/2025 14:24       58  Newcastle  1m 2f 42y           2242   5234   \n",
      "4  1/1/2025 14:24       58  Newcastle  1m 2f 42y           2242   5234   \n",
      "\n",
      "      Going               Horse          Trainer          Jockey  ...  \\\n",
      "0  Standard  Signora Bellissima      Gemma Tutty       S D Bowen  ...   \n",
      "1  Standard      Sonnerie Power  Michael Appleby    Jason Watson  ...   \n",
      "2  Standard          Ribba Hill       Grant Tuer   Harrison Shaw  ...   \n",
      "3  Standard       Orange N Blue        Ruth Carr  James Sullivan  ...   \n",
      "4  Standard       Ever Hopefull    Archie Watson     Luke Morris  ...   \n",
      "\n",
      "   Speed_2ndPreviousRun   NMFPLTO  MarketOdds_PreviousRun  \\\n",
      "0                  43.0  0.000000                  107.41   \n",
      "1                  66.0  0.750000                   35.63   \n",
      "2                  61.0  0.692308                   16.50   \n",
      "3                  60.0  0.000000                   20.69   \n",
      "4                  55.0  0.875000                   18.50   \n",
      "\n",
      "   MarketOdds_2ndPreviousRun  TrainerRating  JockeyRating  daysSinceLastRun  \\\n",
      "0                      54.60       2.323861      2.759082              22.0   \n",
      "1                      55.00       2.386983      2.287354              23.0   \n",
      "2                      12.26       2.335985      2.735036             185.0   \n",
      "3                       4.25       2.669191      2.912424              15.0   \n",
      "4                       7.77       2.238414      2.458009              18.0   \n",
      "\n",
      "   SireRating  DamsireRating  meanRunners  \n",
      "0    2.998003       0.451086        10.75  \n",
      "1    2.545097       0.471986        10.75  \n",
      "2    2.857337       0.451803         6.50  \n",
      "3    2.581940       0.496013         9.25  \n",
      "4    2.644846       0.458226         8.50  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "\n",
    "# Load test and train data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# view columns\n",
    "print(\"Train data columns:\")\n",
    "print(train.columns.tolist())\n",
    "\n",
    "print(\"\\nTest data columns:\")\n",
    "print(test.columns.tolist())\n",
    "\n",
    "# preview\n",
    "print(\"Train Data Sample:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nTest Data Sample:\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b51f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52099 entries, 0 to 52098\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Race_Time                  52099 non-null  object \n",
      " 1   Race_ID                    52099 non-null  int64  \n",
      " 2   Course                     52099 non-null  object \n",
      " 3   Distance                   52099 non-null  object \n",
      " 4   distanceYards              52099 non-null  int64  \n",
      " 5   Prize                      52099 non-null  int64  \n",
      " 6   Going                      52099 non-null  object \n",
      " 7   Horse                      52099 non-null  object \n",
      " 8   Trainer                    52099 non-null  object \n",
      " 9   Jockey                     52099 non-null  object \n",
      " 10  betfairSP                  52099 non-null  float64\n",
      " 11  Position                   52099 non-null  int64  \n",
      " 12  timeSecs                   52099 non-null  float64\n",
      " 13  pdsBeaten                  52099 non-null  float64\n",
      " 14  NMFP                       52099 non-null  float64\n",
      " 15  Runners                    52099 non-null  int64  \n",
      " 16  Age                        52099 non-null  int64  \n",
      " 17  Speed_PreviousRun          52007 non-null  float64\n",
      " 18  Speed_2ndPreviousRun       51897 non-null  float64\n",
      " 19  NMFPLTO                    52007 non-null  float64\n",
      " 20  MarketOdds_PreviousRun     52007 non-null  float64\n",
      " 21  MarketOdds_2ndPreviousRun  51897 non-null  float64\n",
      " 22  TrainerRating              52061 non-null  float64\n",
      " 23  JockeyRating               51956 non-null  float64\n",
      " 24  daysSinceLastRun           52033 non-null  float64\n",
      " 25  SireRating                 52098 non-null  float64\n",
      " 26  DamsireRating              52097 non-null  float64\n",
      " 27  meanRunners                51896 non-null  float64\n",
      "dtypes: float64(15), int64(6), object(7)\n",
      "memory usage: 11.1+ MB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11275 entries, 0 to 11274\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Race_Time                  11275 non-null  object \n",
      " 1   Race_ID                    11275 non-null  int64  \n",
      " 2   Course                     11275 non-null  object \n",
      " 3   Distance                   11275 non-null  object \n",
      " 4   distanceYards              11275 non-null  int64  \n",
      " 5   Prize                      11275 non-null  int64  \n",
      " 6   Going                      11275 non-null  object \n",
      " 7   Horse                      11275 non-null  object \n",
      " 8   Trainer                    11275 non-null  object \n",
      " 9   Jockey                     11275 non-null  object \n",
      " 10  betfairSP                  11275 non-null  float64\n",
      " 11  Position                   11275 non-null  int64  \n",
      " 12  timeSecs                   11275 non-null  float64\n",
      " 13  pdsBeaten                  11275 non-null  float64\n",
      " 14  NMFP                       11275 non-null  float64\n",
      " 15  Runners                    11275 non-null  int64  \n",
      " 16  Age                        11275 non-null  int64  \n",
      " 17  Speed_PreviousRun          11259 non-null  float64\n",
      " 18  Speed_2ndPreviousRun       11245 non-null  float64\n",
      " 19  NMFPLTO                    11259 non-null  float64\n",
      " 20  MarketOdds_PreviousRun     11259 non-null  float64\n",
      " 21  MarketOdds_2ndPreviousRun  11245 non-null  float64\n",
      " 22  TrainerRating              11266 non-null  float64\n",
      " 23  JockeyRating               11253 non-null  float64\n",
      " 24  daysSinceLastRun           11262 non-null  float64\n",
      " 25  SireRating                 11274 non-null  float64\n",
      " 26  DamsireRating              11275 non-null  float64\n",
      " 27  meanRunners                11244 non-null  float64\n",
      "dtypes: float64(15), int64(6), object(7)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check data types\n",
    "# Train data \n",
    "print(\"Train Data Info:\")\n",
    "print(train.info())\n",
    "\n",
    "# Test data \n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1a8c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Race_Time', 'Race_ID', 'Course', 'Distance', 'distanceYards', 'Prize', 'Going', 'Horse', 'Trainer', 'Jockey', 'betfairSP', 'Position', 'timeSecs', 'pdsBeaten', 'NMFP', 'Runners', 'Age', 'Speed_PreviousRun', 'Speed_2ndPreviousRun', 'NMFPLTO', 'MarketOdds_PreviousRun', 'MarketOdds_2ndPreviousRun', 'TrainerRating', 'JockeyRating', 'daysSinceLastRun', 'SireRating', 'DamsireRating', 'meanRunners', 'target']\n"
     ]
    }
   ],
   "source": [
    "# defining target position before dropping columns\n",
    "train['target'] = (train['Position'] == 1).astype(int)\n",
    "print(train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e8f2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Race_Time', 'Race_ID', 'Course', 'Distance', 'distanceYards', 'Prize', 'Going', 'Horse', 'Trainer', 'Jockey', 'Runners', 'Age', 'Speed_PreviousRun', 'Speed_2ndPreviousRun', 'NMFPLTO', 'MarketOdds_PreviousRun', 'MarketOdds_2ndPreviousRun', 'TrainerRating', 'JockeyRating', 'daysSinceLastRun', 'SireRating', 'DamsireRating', 'meanRunners', 'target']\n"
     ]
    }
   ],
   "source": [
    "# drop leakage columns\n",
    "dropped_columns = ['betfairSP', 'Position', 'timeSecs', 'pdsBeaten', 'NMFP']\n",
    "train = train.drop(columns=dropped_columns, errors='ignore')\n",
    "test = test.drop(columns=dropped_columns, errors='ignore')\n",
    "print(train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "872b35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "def race_relative_features(df):\n",
    "    race_groups = df.groupby('Race_ID')\n",
    "    df['speed_avg'] = race_groups['Speed_PreviousRun'].transform('mean')\n",
    "    df['speed_diff_from_avg'] = df['Speed_PreviousRun'] - df['speed_avg']\n",
    "    return df\n",
    "\n",
    "train = race_relative_features(train)\n",
    "test = race_relative_features(test)\n",
    "\n",
    "# Encode cat variables\n",
    "train_encoded = pd.get_dummies(train, drop_first=True)\n",
    "test_encoded = pd.get_dummies(test, drop_first=True)\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# train/validation split\n",
    "X = train_encoded.drop(columns=['target'])\n",
    "y = train_encoded['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43819fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_38744\\1381788147.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_with_ids = test_with_ids.groupby('Race_ID', group_keys=False).apply(fix_rounded_sum)\n"
     ]
    }
   ],
   "source": [
    "# Saving identifiers before any encoding or transformation\n",
    "# this will save the original horse names and race IDs , so I can match predictions back to them later\n",
    "# i created a separate copy so i donâ€™t accidentally change the original data.\n",
    "test_ids = test[['Race_ID', 'Horse']].copy()\n",
    "\n",
    "# Predict probabilities each horse winning\n",
    "test_encoded['winning_probs'] = model.predict_proba(test_encoded[X_train.columns])[:, 1]\n",
    "\n",
    "# resetting index and merging with original IDs to combine to one table\n",
    "# made sure both parts line up properly by ignoring old row numbers.\n",
    "test_with_ids = pd.concat([\n",
    "    test_ids.reset_index(drop=True),\n",
    "    test_encoded[['winning_probs']].reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Normalize within each race to add up to 1\n",
    "test_with_ids['winning_probs_normalized'] = test_with_ids.groupby('Race_ID')['winning_probs'].transform(lambda x: x / x.sum())\n",
    "\n",
    "# format to 2dp\n",
    "test_with_ids['winning_probs_rounded'] = test_with_ids['winning_probs_normalized'].round(2)\n",
    "\n",
    "# adjusting one horse per group\n",
    "def fix_rounded_sum(group):\n",
    "    diff = 1 - group['winning_probs_rounded'].sum()\n",
    "    # Adding the difference to the horse with the highest probability\n",
    "    idx = group['winning_probs_rounded'].idxmax()\n",
    "    group.loc[idx, 'winning_probs_rounded'] += diff\n",
    "    return group\n",
    "\n",
    "test_with_ids = test_with_ids.groupby('Race_ID', group_keys=False).apply(fix_rounded_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b35e8f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4278, number of negative: 37401\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5208\n",
      "[LightGBM] [Info] Number of data points in the train set: 41679, number of used features: 908\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\sklearn\\calibration.py:333: UserWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation:\n",
      "Log Loss: 0.30791839826924744\n",
      "Brier Score: 0.08757478033957591\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "\n",
    "# Cleaning feature names first so that LightGBM won't break cos of special characters or spaces\n",
    "def clean_feature_names(df):\n",
    "    import re\n",
    "    df.columns = [re.sub(r'[^a-zA-Z0-9_]', '_', col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# Apply to data\n",
    "X_train_light = clean_feature_names(X_train.select_dtypes(include=['number', 'bool']))\n",
    "X_val_light = clean_feature_names(X_val.select_dtypes(include=['number', 'bool']))\n",
    "test_encoded_clean = clean_feature_names(test_encoded)\n",
    "\n",
    "# Align train and val first\n",
    "X_train_light, X_val_light = X_train_light.align(X_val_light, join='inner', axis=1, fill_value=0)\n",
    "\n",
    "# Then align test with train\n",
    "X_train_light, test_encoded_clean = X_train_light.align(test_encoded_clean, join='inner', axis=1, fill_value=0)\n",
    "\n",
    "# training LightGBM model\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    num_leaves=20,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "lgb.fit(X_train_light, y_train)\n",
    "\n",
    "# calibrating probabilities with validation set\n",
    "calibrator = CalibratedClassifierCV(lgb, method='isotonic', cv='prefit')\n",
    "calibrator.fit(X_val_light, y_val)\n",
    "\n",
    "# predicting on test \n",
    "test_encoded_clean['winning_probs'] = calibrator.predict_proba(test_encoded_clean[X_train_light.columns])[:, 1]\n",
    "\n",
    "# normalizing the predicted probabilities in each race so they sum to 1\n",
    "test_encoded_clean['winning_probs'] /= test_encoded_clean.groupby('Race_ID')['winning_probs'].transform('sum')\n",
    "\n",
    "# merging back the identifiers\n",
    "submission = pd.DataFrame({\n",
    "    'Race_ID': test['Race_ID'].values,  \n",
    "    'Horse': test['Horse'].values,\n",
    "    'winning_probs': test_encoded_clean['winning_probs'].values\n",
    "})\n",
    "submission.columns = ['Race_ID', 'Horse', 'Predicted_Probability']\n",
    "\n",
    "# saving to csv\n",
    "submission.to_csv('Predicted_Probabilities.csv', index=False)\n",
    "\n",
    "# evaluate performance\n",
    "val_probs = calibrator.predict_proba(X_val_light)[:, 1]\n",
    "print(\"Final Model Evaluation:\")\n",
    "print(\"Log Loss:\", log_loss(y_val, val_probs))\n",
    "print(\"Brier Score:\", brier_score_loss(y_val, val_probs))\n",
    "\n",
    "# i have a log loss of 0.31 and a brier score of 0.09 \n",
    "# via this, i can know how confident and correct the model is and i can also\n",
    "# measure how close predicted probabilities are to actual outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5a2edca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Race probability sums (should all be 1.0):\n",
      "Race_ID\n",
      "58     1.0\n",
      "59     1.0\n",
      "60     1.0\n",
      "61     1.0\n",
      "62     1.0\n",
      "63     1.0\n",
      "64     1.0\n",
      "169    1.0\n",
      "170    1.0\n",
      "171    1.0\n",
      "Name: Predicted_Probability, dtype: float64\n",
      "Race_ID\n",
      "55195    1.0\n",
      "55196    1.0\n",
      "55197    1.0\n",
      "55198    1.0\n",
      "55199    1.0\n",
      "55310    1.0\n",
      "55311    1.0\n",
      "55312    1.0\n",
      "55313    1.0\n",
      "55314    1.0\n",
      "Name: Predicted_Probability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#  checking per-race sums\n",
    "race_sums = submission.groupby('Race_ID')['Predicted_Probability'].sum().round(5)\n",
    "print(\"\\n Race probability sums (should all be 1.0):\")\n",
    "print(race_sums.head(10))\n",
    "print(race_sums.tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
